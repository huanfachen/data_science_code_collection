{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Cross Validation in Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three ways to use **cross valiation** in Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         0.86666667 1.\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "Accuracy: 0.97 (+/- 0.09)\n",
      "Cross validation splitter:  StratifiedKFold(n_splits=10, random_state=10, shuffle=True)\n",
      "Cross validation score: 0.9800 (+/-0.0611)\n"
     ]
    }
   ],
   "source": [
    "# method 1: using cross_val_score and StratifiedKFold\n",
    "\n",
    "# In the cross_val_score function: if the parameter cv is int or None, and if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used (but without shuffling the records). In all other cases, KFold is used.\n",
    "# If shuffuling the records is needed before data splitting, it is recommended to create a StratifiedKFold object and use it with cross_val_score\n",
    "\n",
    "cv_fold=10\n",
    "random_seed=10\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# CASE 1\n",
    "# using cross_val_score without shuffling records\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "# Note: y should be an array\n",
    "scores = cross_val_score(clf, X, y, cv=cv_fold)\n",
    "# note that this is an array\n",
    "print(scores) \n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# CASE 2:\n",
    "# using a StratifiedKFold splitter and cross_val_score. This enables shuffling of records\n",
    "# If shuffle is False, don't set the random_state\n",
    "skf = StratifiedKFold(n_splits=cv_fold, shuffle=True, random_state=random_seed)\n",
    "print(\"Cross validation splitter: \", skf)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, X, y, cv=skf)\n",
    "\n",
    "print(\"Cross validation score: %0.4f (+/-%0.4f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=100, shuffle=True)\n",
      "Cross validation score: 0.9733 (+/-0.0653)\n"
     ]
    }
   ],
   "source": [
    "# method 2: pre-processing the training/testing data before each cross validation iteration\n",
    "# Note: X and y should be an array instead of dataframe or Series\n",
    "\n",
    "cv_fold=10\n",
    "random_seed=100\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "list_train_accuracy = []\n",
    "list_test_accuracy = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=cv_fold, shuffle=True, random_state=random_seed)\n",
    "print(skf)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # insert processing work on train/test data here\n",
    "    \n",
    "    clf = svm.SVC(kernel='linear', C=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # append the accuracy to the lists\n",
    "    list_train_accuracy.append(clf.score(X_train, y_train))\n",
    "    list_test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "print(\"Cross validation score: %0.4f (+/-%0.4f)\" % (np.mean(list_test_accuracy), np.std(list_test_accuracy) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.9667 (+/-0.0894)\n"
     ]
    }
   ],
   "source": [
    "# method 3: using Pipeline to do data transformation with held out data\n",
    "\n",
    "# This is similar to method 2 but more concise. It is suited for simple preprocessing.\n",
    "\n",
    "# Just as it is important to test a predictor on data held-out from training, preprocessing (such as standardization, feature selection, etc.) and similar data transformations similarly should be learnt from a training set and applied to held-out data for prediction\n",
    "# An example of learning standardization from a training set and applying it to the held-out data\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "clf.score(X_test_transformed, y_test)\n",
    "\n",
    "# combining with cross validation\n",
    "# A Pipeline makes it easier to compose estimators, providing this behavior under cross-validation:\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "scores = cross_val_score(clf, X, y, cv=cv_fold)\n",
    "print(\"Cross validation score: %0.4f (+/-%0.4f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test_tf]",
   "language": "python",
   "name": "conda-env-test_tf-py-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
